{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ee1df8e",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#HOME-CREDIT-MODELING-ASSIGNMENT-GROUP-2---Justin-Hamilton-Contribution\" data-toc-modified-id=\"HOME-CREDIT-MODELING-ASSIGNMENT-GROUP-2---Justin-Hamilton-Contribution-1\">HOME CREDIT MODELING ASSIGNMENT GROUP 2 - Justin Hamilton Contribution</a></span></li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-2\">Data Preparation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Importing-Necessary-Packages\" data-toc-modified-id=\"Importing-Necessary-Packages-2.1\">Importing Necessary Packages</a></span></li><li><span><a href=\"#Making-the-dataframes-for-each-of-our-CSV-files\" data-toc-modified-id=\"Making-the-dataframes-for-each-of-our-CSV-files-2.2\">Making the dataframes for each of our CSV files</a></span></li><li><span><a href=\"#Combining-the-DFs-for-our-Analysis\" data-toc-modified-id=\"Combining-the-DFs-for-our-Analysis-2.3\">Combining the DFs for our Analysis</a></span></li><li><span><a href=\"#Multiple-Regression-Models\" data-toc-modified-id=\"Multiple-Regression-Models-2.4\">Multiple Regression Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fitting-several-different-logistic-regression-models-using-different-interactions\" data-toc-modified-id=\"Fitting-several-different-logistic-regression-models-using-different-interactions-2.4.1\">Fitting several different logistic regression models using different interactions</a></span></li><li><span><a href=\"#Attempting-for-the-Up-and-Down-Sampling-for-the-Logistic-Regression-Model\" data-toc-modified-id=\"Attempting-for-the-Up-and-Down-Sampling-for-the-Logistic-Regression-Model-2.4.2\">Attempting for the Up and Down Sampling for the Logistic Regression Model</a></span></li><li><span><a href=\"#Hyper-Parameter-Tuning-of-the-Logistic-Regressions\" data-toc-modified-id=\"Hyper-Parameter-Tuning-of-the-Logistic-Regressions-2.4.3\">Hyper Parameter Tuning of the Logistic Regressions</a></span></li><li><span><a href=\"#Model-performance-of-Best-Logistic-Regression-Model\" data-toc-modified-id=\"Model-performance-of-Best-Logistic-Regression-Model-2.4.4\">Model performance of Best Logistic Regression Model</a></span></li><li><span><a href=\"#Features-of-the-Best-Logistic-Model\" data-toc-modified-id=\"Features-of-the-Best-Logistic-Model-2.4.5\">Features of the Best Logistic Model</a></span></li><li><span><a href=\"#Prediction-on-the-Test-Set\" data-toc-modified-id=\"Prediction-on-the-Test-Set-2.4.6\">Prediction on the Test Set</a></span></li></ul></li><li><span><a href=\"#Random-Forest-Classification-Model\" data-toc-modified-id=\"Random-Forest-Classification-Model-2.5\">Random Forest Classification Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-the-Random-Forest-Classification-and-printing-the-Accuracy-and-AUC-of-the-Model\" data-toc-modified-id=\"Creating-the-Random-Forest-Classification-and-printing-the-Accuracy-and-AUC-of-the-Model-2.5.1\">Creating the Random Forest Classification and printing the Accuracy and AUC of the Model</a></span></li><li><span><a href=\"#Attempting-for-the-Up-and-Down-Sampling-for-the-Random-Forest-Model\" data-toc-modified-id=\"Attempting-for-the-Up-and-Down-Sampling-for-the-Random-Forest-Model-2.5.2\">Attempting for the Up and Down Sampling for the Random Forest Model</a></span></li><li><span><a href=\"#Hyper-Parameters\" data-toc-modified-id=\"Hyper-Parameters-2.5.3\">Hyper Parameters</a></span></li><li><span><a href=\"#Evaluating-the-Best-Model-Performance-of-the-Random-Classification\" data-toc-modified-id=\"Evaluating-the-Best-Model-Performance-of-the-Random-Classification-2.5.4\">Evaluating the Best Model Performance of the Random Classification</a></span></li><li><span><a href=\"#Features-of-the-Best-Random-Forest-Classification-Model\" data-toc-modified-id=\"Features-of-the-Best-Random-Forest-Classification-Model-2.5.5\">Features of the Best Random Forest Classification Model</a></span></li><li><span><a href=\"#Prediction-on-the-Test-Set\" data-toc-modified-id=\"Prediction-on-the-Test-Set-2.5.6\">Prediction on the Test Set</a></span></li></ul></li><li><span><a href=\"#Ensemble-Model\" data-toc-modified-id=\"Ensemble-Model-2.6\">Ensemble Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-the-Ensemble-Model-with-the-RandomForest,-Logistic-Regression,-and-Gradient-Boosting-Models\" data-toc-modified-id=\"Creating-the-Ensemble-Model-with-the-RandomForest,-Logistic-Regression,-and-Gradient-Boosting-Models-2.6.1\">Creating the Ensemble Model with the RandomForest, Logistic Regression, and Gradient Boosting Models</a></span></li><li><span><a href=\"#Up-and-Down-Sampling\" data-toc-modified-id=\"Up-and-Down-Sampling-2.6.2\">Up and Down Sampling</a></span></li><li><span><a href=\"#Hyper-Parameters\" data-toc-modified-id=\"Hyper-Parameters-2.6.3\">Hyper Parameters</a></span></li><li><span><a href=\"#Evaluating-the-Best-of-the-Ensemble-Model\" data-toc-modified-id=\"Evaluating-the-Best-of-the-Ensemble-Model-2.6.4\">Evaluating the Best of the Ensemble Model</a></span></li><li><span><a href=\"#Features-of-the-Best-Ensemble-Model\" data-toc-modified-id=\"Features-of-the-Best-Ensemble-Model-2.6.5\">Features of the Best Ensemble Model</a></span></li><li><span><a href=\"#Prediction-on-the-Test-Set\" data-toc-modified-id=\"Prediction-on-the-Test-Set-2.6.6\">Prediction on the Test Set</a></span></li></ul></li></ul></li><li><span><a href=\"#Model-Performances-Summary\" data-toc-modified-id=\"Model-Performances-Summary-3\">Model Performances Summary</a></span></li><li><span><a href=\"#Results-Summary\" data-toc-modified-id=\"Results-Summary-4\">Results Summary</a></span></li><li><span><a href=\"#Justin-Hamilton-Individual-Contribution-Summary\" data-toc-modified-id=\"Justin-Hamilton-Individual-Contribution-Summary-5\">Justin Hamilton Individual Contribution Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd2105",
   "metadata": {},
   "source": [
    "# HOME CREDIT MODELING ASSIGNMENT GROUP 2 - Justin Hamilton Contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da463f2b",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbccabc",
   "metadata": {},
   "source": [
    "## Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f26ae493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas is already installed.\n",
      "numpy is already installed.\n",
      "matplotlib is already installed.\n",
      "xgboost is already installed.\n",
      "imbalanced-learn is not installed. Installing...\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\jusha\\new folder\\lib\\site-packages (0.10.1)scipy is already installed.\n",
      "sklearn is already installed.\n",
      "\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\jusha\\new folder\\lib\\site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\jusha\\new folder\\lib\\site-packages (from imbalanced-learn) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\jusha\\new folder\\lib\\site-packages (from imbalanced-learn) (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jusha\\new folder\\lib\\site-packages (from imbalanced-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\jusha\\new folder\\lib\\site-packages (from imbalanced-learn) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "# List of required packages\n",
    "required_packages = [\n",
    "    'pandas',\n",
    "    'numpy',\n",
    "    'matplotlib',\n",
    "    'xgboost',\n",
    "    'imbalanced-learn',\n",
    "    'scipy',\n",
    "    'sklearn',\n",
    "]\n",
    "\n",
    "# Check and install missing packages\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "        print(f\"{package} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"{package} is not installed. Installing...\")\n",
    "        !pip install {package}\n",
    "\n",
    "# Import the required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Additional configurations or settings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f9835c",
   "metadata": {},
   "source": [
    "Many of these packages have already been installed. Each of these packages serves different purposes within our code for each of the modeling. All of the packages have imported correctly and have succesfully been installed for use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362a6437",
   "metadata": {},
   "source": [
    "## Making the dataframes for each of our CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ffa8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Dataframes of each of the CSV Files\n",
    "\n",
    "applicationtestDF = pd.read_csv(\"application_test.csv\")\n",
    "applicationtrainDF = pd.read_csv(\"application_train.csv\")\n",
    "bureauDF = pd.read_csv(\"bureau.csv\")\n",
    "bureaubalanceDF = pd.read_csv(\"bureau_balance.csv\")\n",
    "creditcardbalanceDF = pd.read_csv(\"credit_card_balance.csv\")\n",
    "installmentpaymentsDF = pd.read_csv(\"installments_payments.csv\")\n",
    "poscashDF = pd.read_csv(\"POS_CASH_balance.csv\")\n",
    "previousDF = pd.read_csv(\"previous_application.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c384f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48744, 121)\n",
      "(307511, 122)\n",
      "(1716428, 17)\n",
      "(27299925, 3)\n",
      "(3840312, 23)\n",
      "(13605401, 8)\n",
      "(10001358, 8)\n",
      "(1670214, 37)\n"
     ]
    }
   ],
   "source": [
    "#Shape of datasets\n",
    "print(applicationtestDF.shape)\n",
    "print(applicationtrainDF.shape)\n",
    "print(bureauDF.shape)\n",
    "print(bureaubalanceDF.shape)\n",
    "print(creditcardbalanceDF.shape)\n",
    "print(installmentpaymentsDF.shape)\n",
    "print(poscashDF.shape)\n",
    "print(previousDF.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704efea4",
   "metadata": {},
   "source": [
    "Each of the CSV were loaded and installed successfully. Due to the size of each of the CSV files, we have to be selected as to what files to use because it would require too much computation power to use all. Many of the CSV files have data points that are shared in common with other files. We will go into more analysis of which ones to combine into our aggregation of the data sets in our future analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6185a9",
   "metadata": {},
   "source": [
    "## Combining the DFs for our Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df43cccf",
   "metadata": {},
   "source": [
    "***The original approach that we took to getting the DF into one combined Dataframe to analyze as best as possible was to take this approach***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b08a6a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Combine the DataFrames\n",
    "# combined_df = pd.concat([applicationtestDF, applicationtrainDF, bureauDF, bureaubalanceDF,\n",
    "#                          creditcardbalanceDF, installmentpaymentsDF, poscashDF, previousDF])\n",
    "\n",
    "\n",
    "# Remove missing values (NA)\n",
    "# combined_df = combined_df.dropna()\n",
    "\n",
    "# # Remove duplicates from the combined DataFrame\n",
    "# combined_df = combined_df.drop_duplicates()\n",
    "\n",
    "# # Reset the index\n",
    "# combined_df = combined_df.reset_index(drop=True)\n",
    "\n",
    "# # Print the head of the combined DataFrame\n",
    "# combined_df.head()\n",
    "\n",
    "\n",
    "# # Print the data types of each column\n",
    "# combined_df.dtypes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f0b525",
   "metadata": {},
   "source": [
    "However, this approach took up too much computational power to execute due to the size of the data. The append() function was then tried to be used other than the concat() to save memory. This execution was not very appropriate because each of our devices did not have the computation power at first to just combine all datasets into one. We then had decided to continue on and try to use CSV files that we felt are only relevant to our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "478b5766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df = pd.DataFrame()  # Initialize an empty DataFrame\n",
    "\n",
    "# # List of DataFrames to be combined\n",
    "# dataframes = [applicationtestDF, applicationtrainDF, bureauDF, bureaubalanceDF,\n",
    "#               creditcardbalanceDF, installmentpaymentsDF, poscashDF, previousDF]\n",
    "\n",
    "# # Combine DataFrames in smaller batches\n",
    "# for df in dataframes:\n",
    "#     combined_df = combined_df.append(df, ignore_index=True)\n",
    "\n",
    "# # Remove missing values (NA)\n",
    "# combined_df = combined_df.dropna()\n",
    "\n",
    "# # Remove duplicates from the combined DataFrame\n",
    "# combined_df = combined_df.drop_duplicates()\n",
    "\n",
    "# # Reset the index\n",
    "# combined_df = combined_df.reset_index(drop=True)\n",
    "\n",
    "# # Print the head of the combined DataFrame\n",
    "# combined_df.head()\n",
    "\n",
    "# # Print the data types of each column\n",
    "# combined_df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1372283",
   "metadata": {},
   "source": [
    "This method did not work. So We then aggregated some of the values based upon the averages of each datasets. We thought the count of days since overdue payments on both credit card balance and the bureau tables would be good to examine. This method gave us a much better output. By using merge() rather than concat() we are able to merge datasets that fit within computation and add elements to understand for our modeling. We have chosen the creditcardbalance and bureauDF because these dataframes contain much of the same info from the other DF. This information also can tell us how customer behavior may lead to default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7663110d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 124)\n",
      "(48744, 123)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "      <th>SK_DPD</th>\n",
       "      <th>CREDIT_DAY_OVERDUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100008</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>490495.5</td>\n",
       "      <td>27517.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100009</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>1560726.0</td>\n",
       "      <td>41301.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100010</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>1530000.0</td>\n",
       "      <td>42075.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100011</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>1019610.0</td>\n",
       "      <td>33826.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100012</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>405000.0</td>\n",
       "      <td>20250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "5      100008       0         Cash loans           M            N   \n",
       "6      100009       0         Cash loans           F            Y   \n",
       "7      100010       0         Cash loans           M            Y   \n",
       "8      100011       0         Cash loans           F            N   \n",
       "9      100012       0    Revolving loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "5               Y             0           99000.0    490495.5      27517.5   \n",
       "6               Y             1          171000.0   1560726.0      41301.0   \n",
       "7               Y             0          360000.0   1530000.0      42075.0   \n",
       "8               Y             0          112500.0   1019610.0      33826.5   \n",
       "9               Y             0          135000.0    405000.0      20250.0   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_20 FLAG_DOCUMENT_21 AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0  ...                 0                0                        0.0   \n",
       "1  ...                 0                0                        0.0   \n",
       "2  ...                 0                0                        0.0   \n",
       "3  ...                 0                0                        NaN   \n",
       "4  ...                 0                0                        0.0   \n",
       "5  ...                 0                0                        0.0   \n",
       "6  ...                 0                0                        0.0   \n",
       "7  ...                 0                0                        0.0   \n",
       "8  ...                 0                0                        0.0   \n",
       "9  ...                 0                0                        NaN   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_DAY AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                       0.0                        0.0   \n",
       "3                       NaN                        NaN   \n",
       "4                       0.0                        0.0   \n",
       "5                       0.0                        0.0   \n",
       "6                       0.0                        0.0   \n",
       "7                       0.0                        0.0   \n",
       "8                       0.0                        0.0   \n",
       "9                       NaN                        NaN   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                       0.0                        0.0   \n",
       "3                       NaN                        NaN   \n",
       "4                       0.0                        0.0   \n",
       "5                       0.0                        1.0   \n",
       "6                       1.0                        1.0   \n",
       "7                       0.0                        0.0   \n",
       "8                       0.0                        0.0   \n",
       "9                       NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_YEAR  SK_DPD  CREDIT_DAY_OVERDUE  \n",
       "0                         1.0     0.0                 0.0  \n",
       "1                         0.0     0.0                 0.0  \n",
       "2                         0.0     0.0                 0.0  \n",
       "3                         NaN     0.0                 0.0  \n",
       "4                         0.0     0.0                 0.0  \n",
       "5                         1.0     0.0                 0.0  \n",
       "6                         2.0     0.0                 0.0  \n",
       "7                         0.0     0.0                 0.0  \n",
       "8                         1.0     0.0                 0.0  \n",
       "9                         NaN     0.0                 0.0  \n",
       "\n",
       "[10 rows x 124 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate average 'SK_DPD' values in credit_card_balance.csv\n",
    "average_sk_dpd = creditcardbalanceDF.groupby('SK_ID_CURR')['SK_DPD'].mean().reset_index()\n",
    "\n",
    "#Merge average_sk_dpd with train_data based on 'SK_ID_CURR'\n",
    "train_data = applicationtrainDF.merge(average_sk_dpd, on='SK_ID_CURR', how='left')\n",
    "\n",
    "#Merge average_sk_dpd with test_data based on 'SK_ID_CURR'\n",
    "test_data = applicationtestDF.merge(average_sk_dpd, on='SK_ID_CURR', how='left')\n",
    "\n",
    "#Fill missing values with 0\n",
    "train_data['SK_DPD'] = train_data['SK_DPD'].fillna(0)\n",
    "test_data['SK_DPD'] = test_data['SK_DPD'].fillna(0)\n",
    "\n",
    "#Calculate average 'CREDIT_DAY_OVERDUE' values in bureau.csv\n",
    "average_credit_day_overdue = bureauDF.groupby('SK_ID_CURR')['CREDIT_DAY_OVERDUE'].mean().reset_index()\n",
    "\n",
    "#Merge average_credit_day_overdue with train_data based on 'SK_ID_CURR'\n",
    "train_data = train_data.merge(average_credit_day_overdue, on='SK_ID_CURR', how='left')\n",
    "\n",
    "#Merge average_credit_day_overdue with test_data based on 'SK_ID_CURR'\n",
    "test_data = test_data.merge(average_credit_day_overdue, on='SK_ID_CURR', how='left')\n",
    "\n",
    "#Fill missing values with 0\n",
    "train_data['CREDIT_DAY_OVERDUE'] = train_data['CREDIT_DAY_OVERDUE'].fillna(0)\n",
    "test_data['CREDIT_DAY_OVERDUE'] = test_data['CREDIT_DAY_OVERDUE'].fillna(0)\n",
    "\n",
    "#Shape of the joined datasets\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "#First 10 rows on the joined dataset\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adeec0f",
   "metadata": {},
   "source": [
    "This method worked a lot better to get our dataframes merged to set aside for our testing and training datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3fbbf7",
   "metadata": {},
   "source": [
    "## Multiple Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c39773",
   "metadata": {},
   "source": [
    "### Fitting several different logistic regression models using different interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "da5392fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime for generating interaction terms: 11.300916910171509 seconds\n",
      "Runtime for fitting model with interactions: 18.78170418739319 seconds\n",
      "Runtime for preparing validation data: 2.673457384109497 seconds\n",
      "Runtime for making predictions: 1.056178331375122 seconds\n",
      "Runtime for evaluating model performance: 0.1746351718902588 seconds\n",
      "\n",
      "Model without interactions:\n",
      "Accuracy: 0.9195161211648212\n",
      "AUC: 0.6203350955928995\n",
      "\n",
      "Model with interactions:\n",
      "Accuracy: 0.9195323805342829\n",
      "AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Generate interaction terms\n",
    "poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "start_time = time.time()\n",
    "X_train_with_interactions = poly.fit_transform(X_train)\n",
    "end_time = time.time()\n",
    "\n",
    "# Fit logistic regression models with and without interaction terms\n",
    "model_without_interactions = LogisticRegression()\n",
    "model_without_interactions.fit(X_train, y_train)\n",
    "\n",
    "model_with_interactions = LogisticRegression()\n",
    "start_time_with_interactions = time.time()\n",
    "model_with_interactions.fit(X_train_with_interactions, y_train)\n",
    "end_time_with_interactions = time.time()\n",
    "\n",
    "# Prepare validation data\n",
    "start_time_val = time.time()\n",
    "X_val_with_interactions = poly.transform(X_val)\n",
    "end_time_val = time.time()\n",
    "\n",
    "# Make predictions on the validation set\n",
    "start_time_preds = time.time()\n",
    "preds_without_interactions = model_without_interactions.predict(X_val)\n",
    "probs_without_interactions = model_without_interactions.predict_proba(X_val)[:, 1]\n",
    "\n",
    "preds_with_interactions = model_with_interactions.predict(X_val_with_interactions)\n",
    "probs_with_interactions = model_with_interactions.predict_proba(X_val_with_interactions)[:, 1]\n",
    "end_time_preds = time.time()\n",
    "\n",
    "# Evaluate model performance\n",
    "start_time_eval = time.time()\n",
    "accuracy_without_interactions = accuracy_score(y_val, preds_without_interactions)\n",
    "auc_without_interactions = roc_auc_score(y_val, probs_without_interactions)\n",
    "\n",
    "accuracy_with_interactions = accuracy_score(y_val, preds_with_interactions)\n",
    "auc_with_interactions = roc_auc_score(y_val, probs_with_interactions)\n",
    "end_time_eval = time.time()\n",
    "\n",
    "# Print the runtimes\n",
    "print(\"Runtime for generating interaction terms:\", end_time - start_time, \"seconds\")\n",
    "print(\"Runtime for fitting model with interactions:\", end_time_with_interactions - start_time_with_interactions, \"seconds\")\n",
    "print(\"Runtime for preparing validation data:\", end_time_val - start_time_val, \"seconds\")\n",
    "print(\"Runtime for making predictions:\", end_time_preds - start_time_preds, \"seconds\")\n",
    "print(\"Runtime for evaluating model performance:\", end_time_eval - start_time_eval, \"seconds\")\n",
    "\n",
    "# Compare model performance\n",
    "print(\"\\nModel without interactions:\")\n",
    "print(\"Accuracy:\", accuracy_without_interactions)\n",
    "print(\"AUC:\", auc_without_interactions)\n",
    "\n",
    "print(\"\\nModel with interactions:\")\n",
    "print(\"Accuracy:\", accuracy_with_interactions)\n",
    "print(\"AUC:\", auc_with_interactions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f922258",
   "metadata": {},
   "source": [
    "From our output of the logistic regression modeling, we see that the model without interactions had a accuracy of 91.9516% and an AUC of .62. The model with interactions has a accuracy of 91.9532% but an AUC of .5.\n",
    "\n",
    "\n",
    "There may be a higher AUC within the model without interactions because there is less to consider in the effect that interactions can have one the target variable. Although our AUC is lower for the model with interactions, this may because now we are looking at the bigger picture with all interactive variables and we are resulting in getting a higher accuracy of the logistic regression model when we include the interactions. Not as high of an AUC as it should be because this may signal overfitting or random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f943118",
   "metadata": {},
   "source": [
    "### Attempting for the Up and Down Sampling for the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bbb82942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution (Before):\n",
      "0    226132\n",
      "1     19876\n",
      "Name: TARGET, dtype: int64\n",
      "Upsampling Runtime: 1.366769790649414 seconds\n",
      "Downsampling Runtime: 0.23794841766357422 seconds\n",
      "Upsampled Training Runtime: 7.301072359085083 seconds\n",
      "Downsampled Training Runtime: 0.6300501823425293 seconds\n",
      "Original Prediction Runtime: 0.03173041343688965 seconds\n",
      "Accuracy (Original): 0.5965237468090987\n",
      "Accuracy (Upsampled): 0.5941986569760824\n",
      "Accuracy (Downsampled): 0.5965237468090987\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Analyze class distribution in the training set\n",
    "class_counts = y_train.value_counts()\n",
    "print(\"Class Distribution (Before):\")\n",
    "print(class_counts)\n",
    "\n",
    "# Upsample the minority class\n",
    "df_majority = X_train[y_train == 0]\n",
    "df_minority = X_train[y_train == 1]\n",
    "\n",
    "start_time_upsample = time.time()\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "X_train_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "y_train_upsampled = pd.Series([0] * len(df_majority) + [1] * len(df_minority_upsampled))\n",
    "end_time_upsample = time.time()\n",
    "\n",
    "# Downsample the majority class\n",
    "start_time_downsample = time.time()\n",
    "df_majority_downsampled = resample(df_majority, replace=False, n_samples=len(df_minority), random_state=42)\n",
    "X_train_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "y_train_downsampled = pd.Series([0] * len(df_majority_downsampled) + [1] * len(df_minority))\n",
    "end_time_downsample = time.time()\n",
    "\n",
    "# Train and evaluate models on upsampled and downsampled data\n",
    "model = LogisticRegression()  # Initialize the LogisticRegression model\n",
    "\n",
    "# Train on upsampled data\n",
    "start_time_train_upsampled = time.time()\n",
    "model.fit(X_train_upsampled, y_train_upsampled)\n",
    "y_pred_upsampled = model.predict(X_val)\n",
    "accuracy_upsampled = accuracy_score(y_val, y_pred_upsampled)\n",
    "end_time_train_upsampled = time.time()\n",
    "\n",
    "# Train on downsampled data\n",
    "start_time_train_downsampled = time.time()\n",
    "model.fit(X_train_downsampled, y_train_downsampled)\n",
    "y_pred_downsampled = model.predict(X_val)\n",
    "accuracy_downsampled = accuracy_score(y_val, y_pred_downsampled)\n",
    "end_time_train_downsampled = time.time()\n",
    "\n",
    "# Compute predictions for original data\n",
    "start_time_pred_original = time.time()\n",
    "y_pred_original = model.predict(X_val)\n",
    "accuracy_original = accuracy_score(y_val, y_pred_original)\n",
    "end_time_pred_original = time.time()\n",
    "\n",
    "# Print the runtimes\n",
    "print(\"Upsampling Runtime:\", end_time_upsample - start_time_upsample, \"seconds\")\n",
    "print(\"Downsampling Runtime:\", end_time_downsample - start_time_downsample, \"seconds\")\n",
    "print(\"Upsampled Training Runtime:\", end_time_train_upsampled - start_time_train_upsampled, \"seconds\")\n",
    "print(\"Downsampled Training Runtime:\", end_time_train_downsampled - start_time_train_downsampled, \"seconds\")\n",
    "print(\"Original Prediction Runtime:\", end_time_pred_original - start_time_pred_original, \"seconds\")\n",
    "\n",
    "# Compare model performance\n",
    "print(\"Accuracy (Original):\", accuracy_original)\n",
    "print(\"Accuracy (Upsampled):\", accuracy_upsampled)\n",
    "print(\"Accuracy (Downsampled):\", accuracy_downsampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e84275",
   "metadata": {},
   "source": [
    "When considering whether to up or downsample the dataset, we see that upsampling gives us the lowest accuracy within our modeling of only being 59.41% accurate in predicting for the target variable.\n",
    "\n",
    "We see that the original and downsample of the logistic regression give us the same and higher accuracy of 59.65%. Because of this when we perform our hyper parameters and evaluations within the logistic regression model we are going to keep our original data rather than the up or down sampled versions of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f242f20",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning of the Logistic Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c8c77faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Runtime: 364.85560846328735 seconds\n",
      "Training Runtime: 4.806471347808838 seconds\n",
      "Prediction Runtime: 0.051279544830322266 seconds\n",
      "Evaluation Runtime: 0.0 seconds\n",
      "Best Hyperparameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best Score: 0.9192018146332195\n",
      "Accuracy: 0.9195161211648212\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the hyperparameters and their search space\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "start_time = time.time()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "# Get the best hyperparameter values and model performance\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "start_time_train = time.time()\n",
    "best_model = LogisticRegression(**best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "end_time_train = time.time()\n",
    "\n",
    "# Make predictions using the best model\n",
    "start_time_pred = time.time()\n",
    "y_pred = best_model.predict(X_val)\n",
    "end_time_pred = time.time()\n",
    "\n",
    "# Evaluate the model performance\n",
    "start_time_eval = time.time()\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "end_time_eval = time.time()\n",
    "\n",
    "# Print the runtimes\n",
    "print(\"Grid Search Runtime:\", end_time - start_time, \"seconds\")\n",
    "print(\"Training Runtime:\", end_time_train - start_time_train, \"seconds\")\n",
    "print(\"Prediction Runtime:\", end_time_pred - start_time_pred, \"seconds\")\n",
    "print(\"Evaluation Runtime:\", end_time_eval - start_time_eval, \"seconds\")\n",
    "\n",
    "# Print the best hyperparameters and model performance\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbec6e3c",
   "metadata": {},
   "source": [
    "After using hyper parameters, we see a couple of interesting observations. The first of which is that this process takes a long time to complete. Taking about 6 minutes to compute.\n",
    "\n",
    "Within the best hyperparameters for modeling we see that\n",
    "\n",
    "* Because C is .1, suggests a moderately strong regularization is preferred by the model\n",
    "* The penalty being of L2 means that Ridge Regularization will give us our best results\n",
    "* Solver being assigned as liblinear means that this solver is suitable for small to medium size datasets and supports L1 and L2 penalities\n",
    "\n",
    "\n",
    "With the best score being 0.9192018146332195 this means that at the cross validations the mean of the accuracies is 0.9192018146332195. Meaning, that on average at the best parameters the model was performing at a accuracy that is a little too high. This may result because of over fitting within the model performed by the machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c0448",
   "metadata": {},
   "source": [
    "### Model performance of Best Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4141baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Performance:\n",
      "AUC: 0.4999977889020572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96    226132\n",
      "           1       0.00      0.00      0.00     19876\n",
      "\n",
      "    accuracy                           0.92    246008\n",
      "   macro avg       0.46      0.50      0.48    246008\n",
      "weighted avg       0.84      0.92      0.88    246008\n",
      "\n",
      "Train Set Runtime: 0.22581863403320312 seconds\n",
      "Test Set Performance:\n",
      "AUC: 0.49999115889238605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     56554\n",
      "           1       0.00      0.00      0.00      4949\n",
      "\n",
      "    accuracy                           0.92     61503\n",
      "   macro avg       0.46      0.50      0.48     61503\n",
      "weighted avg       0.85      0.92      0.88     61503\n",
      "\n",
      "Test Set Runtime: 0.03416752815246582 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Train set performance\n",
    "start_time_train = time.time()\n",
    "train_pred = best_model.predict(X_train)\n",
    "train_auc = roc_auc_score(y_train, train_pred)\n",
    "end_time_train = time.time()\n",
    "\n",
    "# Print train set performance and runtime\n",
    "print(\"Train Set Performance:\")\n",
    "print(\"AUC:\", train_auc)\n",
    "print(classification_report(y_train, train_pred))\n",
    "print(\"Train Set Runtime:\", end_time_train - start_time_train, \"seconds\")\n",
    "\n",
    "# Test set performance\n",
    "start_time_test = time.time()\n",
    "test_pred = best_model.predict(X_val)\n",
    "test_auc = roc_auc_score(y_val, test_pred)\n",
    "end_time_test = time.time()\n",
    "\n",
    "# Print test set performance and runtime\n",
    "print(\"Test Set Performance:\")\n",
    "print(\"AUC:\", test_auc)\n",
    "print(classification_report(y_val, test_pred))\n",
    "print(\"Test Set Runtime:\", end_time_test - start_time_test, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b11d34c",
   "metadata": {},
   "source": [
    "Under the best parameters set for the Logistic Regression Modeling\n",
    "\n",
    "The Train Set\n",
    "* Has an AUC of 0.4999977889020572. Meaning that the models predictive powers seem to be pretty close to random and the classification power of the model are fairly low.\n",
    "* The precision, recall, and F1 score for the majority class of 0 (Those who do not default) are all very high meaning that the model performs well in identifying the majority class\n",
    "* However the precision, recall, and F1 score for the minority class of 1 (Those who do default) are very low at 0. Meaning that it is difficult for the model to predict those who will default.\n",
    "* This train set does give a 92% accuracy though, largely due to its ability to correctly predict the majority class of those who do not default\n",
    "\n",
    "The Test Set\n",
    "\n",
    "* The evaluation of the Test set performs almost identical to that of the train dataset.\n",
    "\n",
    "\n",
    "This shows us that the Logistic regression model is a model that does accurately and have a power to predict those who are safe to borrow to, which is the purpose of the model. \n",
    "\n",
    "While the AUC may be lower and may suggest low discrimative power in classification, this may be because of overfitting performed within the parameters of the model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5443ac8",
   "metadata": {},
   "source": [
    "### Features of the Best Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "386b73bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Feature  Coefficient\n",
      "33      DAYS_LAST_PHONE_CHANGE   0.00021637\n",
      "10             DAYS_ID_PUBLISH   0.00009348\n",
      "7                   DAYS_BIRTH   0.00008404\n",
      "9            DAYS_REGISTRATION   0.00002685\n",
      "4                  AMT_ANNUITY   0.00000776\n",
      "3                   AMT_CREDIT   0.00000310\n",
      "61          CREDIT_DAY_OVERDUE   0.00000259\n",
      "8                DAYS_EMPLOYED   0.00000052\n",
      "59  AMT_REQ_CREDIT_BUREAU_YEAR   0.00000048\n",
      "60                      SK_DPD   0.00000025\n",
      "Runtime for retrieving coefficients: 0.0 seconds\n",
      "Runtime for creating DataFrame: 0.024721384048461914 seconds\n",
      "Runtime for sorting DataFrame: 0.009205102920532227 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option('display.float_format', lambda x: '%.8f' % x)\n",
    "\n",
    "# Get the feature coefficients and their corresponding names\n",
    "start_time = time.time()\n",
    "coefficients = best_model.coef_[0]\n",
    "feature_names = X_train.columns\n",
    "end_time = time.time()\n",
    "\n",
    "# Create a DataFrame to store the coefficients and feature names\n",
    "start_time_df = time.time()\n",
    "coefficients_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "end_time_df = time.time()\n",
    "\n",
    "# Sort the DataFrame by coefficient magnitude in descending order\n",
    "start_time_sort = time.time()\n",
    "coefficients_df = coefficients_df.sort_values('Coefficient', ascending=False)\n",
    "end_time_sort = time.time()\n",
    "\n",
    "# Display the coefficients and their impact on the target variable\n",
    "print(coefficients_df.head(10))\n",
    "\n",
    "# Print the runtimes\n",
    "print(\"Runtime for retrieving coefficients:\", end_time - start_time, \"seconds\")\n",
    "print(\"Runtime for creating DataFrame:\", end_time_df - start_time_df, \"seconds\")\n",
    "print(\"Runtime for sorting DataFrame:\", end_time_sort - start_time_sort, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbfb126",
   "metadata": {},
   "source": [
    "From this output, we learn that when each of these things increases, so does the likelihood of the person being safe to borrow to increases\n",
    "\n",
    "* Number of days since the clients last owned phone\n",
    "* Number of days since the client changed their ID info\n",
    "* Age in days of the client\n",
    "* Number of days before the application the client change their registration\n",
    "* Loan annuity\n",
    "* Credit amount of the loan\n",
    "* Number of days past due on CB credit at the time of application for related loan\n",
    "* Days before the application the person started current employment\n",
    "* Number of enquiries to Credit Bureau about the client one year\n",
    "* DPD (Days past due) during the month on the previous credit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026fe394",
   "metadata": {},
   "source": [
    "### Prediction on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "94e7abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on the test set\n",
    "test_predictions = best_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2ca85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": test_data[\"SK_ID_CURR\"], \n",
    "    \"TARGET\": test_predictions\n",
    "})\n",
    "\n",
    "#Remove duplicate SK_ID_CURR values\n",
    "submission = submission.drop_duplicates(subset=\"SK_ID_CURR\", keep=\"first\")\n",
    "\n",
    "#Save the submission DataFrame to a CSV file\n",
    "submission.to_csv(\"submission_log2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ce365",
   "metadata": {},
   "source": [
    "When we put this into Kaggle, we get a score of .5 While this may not be as high as anticipated, this does align with the AUC that signaled not as satisfactory results of potentially random guessing within the data set rather than making accurate predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556c621e",
   "metadata": {},
   "source": [
    "## Random Forest Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c33e2",
   "metadata": {},
   "source": [
    "### Creating the Random Forest Classification and printing the Accuracy and AUC of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "af80fb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Runtime: 147.61922216415405 seconds\n",
      "Prediction Runtime: 4.936388731002808 seconds\n",
      "Evaluation Runtime: 0.02080988883972168 seconds\n",
      "Random Forest Model:\n",
      "Accuracy: 0.9196136773815912\n",
      "AUC: 0.7069750901140923\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Fit Random Forest model\n",
    "start_time_fit = time.time()\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "end_time_fit = time.time()\n",
    "\n",
    "# Make predictions with Random Forest model\n",
    "start_time_pred = time.time()\n",
    "rf_preds = rf_model.predict(X_val)\n",
    "rf_probs = rf_model.predict_proba(X_val)[:, 1]\n",
    "end_time_pred = time.time()\n",
    "\n",
    "# Evaluate Random Forest model performance\n",
    "start_time_eval = time.time()\n",
    "rf_accuracy = accuracy_score(y_val, rf_preds)\n",
    "rf_auc = roc_auc_score(y_val, rf_probs)\n",
    "end_time_eval = time.time()\n",
    "\n",
    "# Print the runtimes\n",
    "print(\"Fit Runtime:\", end_time_fit - start_time_fit, \"seconds\")\n",
    "print(\"Prediction Runtime:\", end_time_pred - start_time_pred, \"seconds\")\n",
    "print(\"Evaluation Runtime:\", end_time_eval - start_time_eval, \"seconds\")\n",
    "\n",
    "# Compare model performance\n",
    "print(\"Random Forest Model:\")\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "print(\"AUC:\", rf_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520d382c",
   "metadata": {},
   "source": [
    "When we perform a raw Random Forest Model we see that we get an accuracy of 0.919711233598361 or about 92%. This is a very high accuracy meaning that this model does not do a great job at predicting the accuracy of the majority class. We have an AUC of 0.7069800939416186 meaning that the Random Forest Model has a strong discrimative power to tell if a customer would be a safe borrower or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d527ed",
   "metadata": {},
   "source": [
    "###  Attempting for the Up and Down Sampling for the Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9986e0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution (Before):\n",
      "0    226132\n",
      "1     19876\n",
      "Name: TARGET, dtype: int64\n",
      "Accuracy (Original): 0.6793164561078321\n",
      "Accuracy (Upsampled): 0.9196299367510528\n",
      "Accuracy (Downsampled): 0.6793164561078321\n",
      "Class Distribution Runtime: 0.013184785842895508 seconds\n",
      "Upsampling Runtime: 0.5757849216461182 seconds\n",
      "Downsampling Runtime: 0.07246971130371094 seconds\n",
      "Training Runtime: 213.34045934677124 seconds\n",
      "Prediction Runtime: 1.3933310508728027 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Analyze class distribution in the training set\n",
    "start_time_dist = time.time()\n",
    "class_counts = y_train.value_counts()\n",
    "end_time_dist = time.time()\n",
    "\n",
    "print(\"Class Distribution (Before):\")\n",
    "print(class_counts)\n",
    "\n",
    "# Upsample the minority class\n",
    "start_time_upsample = time.time()\n",
    "df_majority = X_train[y_train == 0]\n",
    "df_minority = X_train[y_train == 1]\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "\n",
    "X_train_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "y_train_upsampled = pd.Series([0] * len(df_majority) + [1] * len(df_minority_upsampled))\n",
    "end_time_upsample = time.time()\n",
    "\n",
    "# Downsample the majority class\n",
    "start_time_downsample = time.time()\n",
    "df_majority_downsampled = resample(df_majority, replace=False, n_samples=len(df_minority), random_state=42)\n",
    "\n",
    "X_train_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "y_train_downsampled = pd.Series([0] * len(df_majority_downsampled) + [1] * len(df_minority))\n",
    "end_time_downsample = time.time()\n",
    "\n",
    "# Train and evaluate models on upsampled and downsampled data\n",
    "start_time_train = time.time()\n",
    "model = RandomForestClassifier()  # Initialize the Random Forest model\n",
    "\n",
    "# Train on upsampled data\n",
    "model.fit(X_train_upsampled, y_train_upsampled)\n",
    "y_pred_upsampled = model.predict(X_val)\n",
    "accuracy_upsampled = accuracy_score(y_val, y_pred_upsampled)\n",
    "\n",
    "# Train on downsampled data\n",
    "model.fit(X_train_downsampled, y_train_downsampled)\n",
    "y_pred_downsampled = model.predict(X_val)\n",
    "accuracy_downsampled = accuracy_score(y_val, y_pred_downsampled)\n",
    "end_time_train = time.time()\n",
    "\n",
    "# Compute predictions for original data\n",
    "start_time_pred = time.time()\n",
    "y_pred_original = model.predict(X_val)\n",
    "accuracy_original = accuracy_score(y_val, y_pred_original)\n",
    "end_time_pred = time.time()\n",
    "\n",
    "# Compare model performance\n",
    "print(\"Accuracy (Original):\", accuracy_original)\n",
    "print(\"Accuracy (Upsampled):\", accuracy_upsampled)\n",
    "print(\"Accuracy (Downsampled):\", accuracy_downsampled)\n",
    "\n",
    "# Print the runtimes\n",
    "print(\"Class Distribution Runtime:\", end_time_dist - start_time_dist, \"seconds\")\n",
    "print(\"Upsampling Runtime:\", end_time_upsample - start_time_upsample, \"seconds\")\n",
    "print(\"Downsampling Runtime:\", end_time_downsample - start_time_downsample, \"seconds\")\n",
    "print(\"Training Runtime:\", end_time_train - start_time_train, \"seconds\")\n",
    "print(\"Prediction Runtime:\", end_time_pred - start_time_pred, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee84880a",
   "metadata": {},
   "source": [
    "When we test the accuracy of the data on the Random Forest Model, we see that it has the highest accuracy when the data is upsampled. Upsampmling gives us an accuracy of 0.9194998617953596 or 91.95%. While the original and downsampled version of the dataset gives us a moderate accuracy of 0.6786823406988277 or 67.87%. Although accuracy may not be as beneficial as using the measurement of AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675ab4bf",
   "metadata": {},
   "source": [
    "### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "08a5b62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None}\n",
      "Best Score: 0.9900522703553676\n",
      "Accuracy: 0.9194185649480513\n",
      "Randomized Search Runtime: 652.6474483013153 seconds\n",
      "Training Runtime: 191.16876101493835 seconds\n",
      "Prediction Runtime: 2.427534341812134 seconds\n",
      "Evaluation Runtime: 0.008106470108032227 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the hyperparameters and their search space\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 5],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform randomized search with cross-validation\n",
    "start_time_search = time.time()\n",
    "# CV 2 was set here rather than 5 because the CV 5 took too much time. Longer than 8 hours. n_iter = 5 \n",
    "# was also set to make the process go faster\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=5, cv=2, scoring='accuracy')\n",
    "# Because our UpSampling had a better accuracy, we are using that here rather than the original \n",
    "random_search.fit(X_train_upsampled, y_train_upsampled)\n",
    "end_time_search = time.time()\n",
    "\n",
    "# Get the best hyperparameter values and model performance\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "start_time_train = time.time()\n",
    "best_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_model.fit(X_train_upsampled, y_train_upsampled)\n",
    "end_time_train = time.time()\n",
    "\n",
    "# Make predictions using the best model\n",
    "start_time_pred = time.time()\n",
    "y_pred = best_model.predict(X_val)\n",
    "end_time_pred = time.time()\n",
    "\n",
    "# Evaluate the model performance\n",
    "start_time_eval = time.time()\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "end_time_eval = time.time()\n",
    "\n",
    "# Print the best hyperparameters and model performance\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the runtimes\n",
    "print(\"Randomized Search Runtime:\", end_time_search - start_time_search, \"seconds\")\n",
    "print(\"Training Runtime:\", end_time_train - start_time_train, \"seconds\")\n",
    "print(\"Prediction Runtime:\", end_time_pred - start_time_pred, \"seconds\")\n",
    "print(\"Evaluation Runtime:\", end_time_eval - start_time_eval, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767dcea1",
   "metadata": {},
   "source": [
    "After using hyper parameters, we see a couple of interesting observations. The first of which is that this process takes a long time to complete. Taking about 14 minutes to compute.\n",
    "\n",
    "Within the best hyperparameters for modeling we see that\n",
    "\n",
    "* Because n_estimators is 100 this means that at the best model, there will be 100 decision trees.\n",
    "* min_samples_split tells us the minimum number of samples required to split into a node. The best is 2. Meaning a node is only split if it contains at least 2 samples\n",
    "* min_samples_leaf is the minimum number of samples required to be at a leaf node. The best value is 1, indicating that a leaf node can have as few as 1 sample.\n",
    "* max_depth is the maximum depth of the tree. The best value is None, which means there is no maximum depth limit, and the tree will grow until all leaves are pure or until all leaves contain a minimum number of samples.\n",
    "\n",
    "\n",
    "With the best score being 0.9900522703553676 meaning that the best score that can be achieved within the model is about .99.  Meaning that the best Random Forest model acheived an average accuracy of 99% during cross validation within the search. Even with cross validation, this may infer that there is oversampling among the data after cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aad144b",
   "metadata": {},
   "source": [
    "### Evaluating the Best Model Performance of the Random Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e0d02ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Performance:\n",
      "AUC: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    226132\n",
      "           1       1.00      1.00      1.00     19876\n",
      "\n",
      "    accuracy                           1.00    246008\n",
      "   macro avg       1.00      1.00      1.00    246008\n",
      "weighted avg       1.00      1.00      1.00    246008\n",
      "\n",
      "Test Set Performance:\n",
      "AUC: 0.507036696323935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     56554\n",
      "           1       0.48      0.02      0.03      4949\n",
      "\n",
      "    accuracy                           0.92     61503\n",
      "   macro avg       0.70      0.51      0.49     61503\n",
      "weighted avg       0.88      0.92      0.88     61503\n",
      "\n",
      "Training Runtime: 9.18987774848938 seconds\n",
      "Testing Runtime: 2.0379745960235596 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Train set performance\n",
    "start_time_train = time.time()\n",
    "train_pred = best_model.predict(X_train)\n",
    "train_auc = roc_auc_score(y_train, train_pred)\n",
    "end_time_train = time.time()\n",
    "\n",
    "print(\"Train Set Performance:\")\n",
    "print(\"AUC:\", train_auc)\n",
    "print(classification_report(y_train, train_pred))\n",
    "\n",
    "# Test set performance\n",
    "start_time_test = time.time()\n",
    "test_pred = best_model.predict(X_val)\n",
    "test_auc = roc_auc_score(y_val, test_pred)\n",
    "end_time_test = time.time()\n",
    "\n",
    "print(\"Test Set Performance:\")\n",
    "print(\"AUC:\", test_auc)\n",
    "print(classification_report(y_val, test_pred))\n",
    "\n",
    "# Print the runtimes\n",
    "print(\"Training Runtime:\", end_time_train - start_time_train, \"seconds\")\n",
    "print(\"Testing Runtime:\", end_time_test - start_time_test, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5d01be",
   "metadata": {},
   "source": [
    "Under the best parameters set for the Random Forest Modeling\n",
    "\n",
    "The Train Set\n",
    "* Has an AUC of 1.0. Meaning that the models predictive powers seem to be low because there is no diversity within the predictions. This could be a result of oversampling within the parameters.\n",
    "* The precision, recall, and F1 score for the majority class of 0 (Those who do not default) are all 1.0. Very high meaning that the model performs well in identifying the majority class, perfection. This is a too high of a rating and could be overfitting.\n",
    "* The precision, recall, and F1 score for the minority class of 1 (Those who do default) are at 1.0. Meaning that the model is a perfect classifier of those that are safe to lend to.\n",
    "* This train set gives us a 100% accuracy rating. Meaning that this model at it's best can predict 100% of the outcomes for the borrower. This is not a good measurement against the train set because it is over fitting to the training data. \n",
    "\n",
    "The Test Set\n",
    "* AUC of AUC: 0.507036696323935. This shows us that within the test set, the model does have a discriminatory power, but it is relatively low.\n",
    "* The precision, recall, and F1 score are .92, 1.00, and .96 when the class of 0 (Those who are save borrowers). This means that the model predicts the class of 0 poorly as the data was overfitted in the process.\n",
    "* The precision, recall, and F1 score are .48, 0.02, and 0.03 when the class of 1 (Those who are NOT save borrowers). This means that the model predicts the class of 1 poorly.\n",
    "* We see that because of the macro average and the weighted average they are unbalanced between the classes. This may be why the model is better at predicting for class 0 than 1. Because of this the AUC would be a better measurement rather than using the accuracy %.\n",
    "* The accuracy is 92% which again shows us that this model is accurate most often when predicting for the majority class of 0 , but not for the class of 1. This is a too high accuracy and the AUC remains a better score for prediction. \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72030a9",
   "metadata": {},
   "source": [
    "### Features of the Best Random Forest Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e1da418b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Feature  Importance\n",
      "27            EXT_SOURCE_2  0.09877625\n",
      "28            EXT_SOURCE_3  0.09503074\n",
      "7               DAYS_BIRTH  0.05982140\n",
      "10         DAYS_ID_PUBLISH  0.05542707\n",
      "4              AMT_ANNUITY  0.05442446\n",
      "9        DAYS_REGISTRATION  0.05414072\n",
      "8            DAYS_EMPLOYED  0.05385393\n",
      "33  DAYS_LAST_PHONE_CHANGE  0.05312109\n",
      "0               SK_ID_CURR  0.05280328\n",
      "3               AMT_CREDIT  0.04984712\n",
      "Runtime: 0.11169624328613281 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Feature importance\n",
    "start_time = time.time()\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store the feature importances\n",
    "importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Display the top 10 most important features\n",
    "print(importance_df.head(10))\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the runtime\n",
    "print(\"Runtime:\", end_time - start_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54f8572",
   "metadata": {},
   "source": [
    "From this output, we learn that the top 10 most important features when seeing if someone is safe to lend money to are based on\n",
    "\n",
    "\n",
    "* Normalized score from external data source\n",
    "* Client's age in days at the time of application\n",
    "* How many days before the application did client change the identity document\n",
    "* Loan annuity\n",
    "* How many days before the application did client change their registration\n",
    "* How many days before the application the person started current employment\n",
    "* Number of days since the client last changed their phone number\n",
    "* ID of loan in our sample\n",
    "* Credit amount of the loan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e114f5",
   "metadata": {},
   "source": [
    "### Prediction on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "91099bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on the test set\n",
    "test_predictions = best_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bb3724c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": test_data[\"SK_ID_CURR\"], \n",
    "    \"TARGET\": test_predictions\n",
    "})\n",
    "\n",
    "#Remove duplicate SK_ID_CURR values\n",
    "submission = submission.drop_duplicates(subset=\"SK_ID_CURR\", keep=\"first\")\n",
    "\n",
    "#Save the submission DataFrame to a CSV file\n",
    "submission.to_csv(\"submission_randomforest3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7592e92",
   "metadata": {},
   "source": [
    "After putting this model into Kaggle, we see that we get a Kaggle score of .50195. This matches our scores of the model both signaling that this model has been overfit and does not give as well predictions for the model as it should."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c902327",
   "metadata": {},
   "source": [
    "## Ensemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e53bcbc",
   "metadata": {},
   "source": [
    "### Creating the Ensemble Model with the RandomForest, Logistic Regression, and Gradient Boosting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "79417dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Random Forrest Classifier Accuracy: 0.9193278267373419\n",
      "Individual Logistic Regression Accuracy: 0.9192018145751357\n",
      "Individual Gradient Boosting Classifier Accuracy: 0.9192790478358427\n",
      "Ensemble Model Accuracy: 0.9196299367510528\n",
      "Ensemble Model Cross-Validation Scores: [0.9192919  0.91925125 0.91925125 0.91931058 0.91918863]\n",
      "Cross-Validation Runtime: 275.05734634399414 seconds\n",
      "Ensemble Cross-Validation Runtime: 1118.3136358261108 seconds\n",
      "Fit Runtime: 297.7979905605316 seconds\n",
      "Prediction Runtime: 2.6046464443206787 seconds\n",
      "Accuracy Calculation Runtime: 0.007262468338012695 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize individual models\n",
    "model1 = RandomForestClassifier()\n",
    "model2 = LogisticRegression()\n",
    "model3 = GradientBoostingClassifier()\n",
    "\n",
    "# Evaluate individual models using cross-validation\n",
    "start_time_cv = time.time()\n",
    "model1_scores = cross_val_score(model1, X_train, y_train, cv=2, scoring='accuracy')\n",
    "model2_scores = cross_val_score(model2, X_train, y_train, cv=2, scoring='accuracy')\n",
    "model3_scores = cross_val_score(model3, X_train, y_train, cv=2, scoring='accuracy')\n",
    "end_time_cv = time.time()\n",
    "\n",
    "# Create the ensemble model\n",
    "ensemble_model = VotingClassifier(estimators=[('model1', model1), ('model2', model2), ('model3', model3)])\n",
    "\n",
    "# Evaluate ensemble model using cross-validation\n",
    "start_time_ensemble_cv = time.time()\n",
    "ensemble_scores = cross_val_score(ensemble_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "end_time_ensemble_cv = time.time()\n",
    "\n",
    "# Fit the ensemble model on the entire training set\n",
    "start_time_fit = time.time()\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "end_time_fit = time.time()\n",
    "\n",
    "# Make predictions with the ensemble model\n",
    "start_time_preds = time.time()\n",
    "ensemble_preds = ensemble_model.predict(X_val)\n",
    "end_time_preds = time.time()\n",
    "\n",
    "# Calculate ensemble model accuracy\n",
    "start_time_accuracy = time.time()\n",
    "# Calculate accuracy for each individual model\n",
    "model1_accuracy = np.mean(model1_scores)\n",
    "model2_accuracy = np.mean(model2_scores)\n",
    "model3_accuracy = np.mean(model3_scores)\n",
    "ensemble_accuracy = accuracy_score(y_val, ensemble_preds)\n",
    "end_time_accuracy = time.time()\n",
    "\n",
    "# Print individual models and ensemble model performance\n",
    "print(\"Individual Random Forrest Classifier Accuracy:\", model1_accuracy)\n",
    "print(\"Individual Logistic Regression Accuracy:\", model2_accuracy)\n",
    "print(\"Individual Gradient Boosting Classifier Accuracy:\", model3_accuracy)\n",
    "print(\"Ensemble Model Accuracy:\", ensemble_accuracy)\n",
    "print(\"Ensemble Model Cross-Validation Scores:\", ensemble_scores)\n",
    "\n",
    "# Print the runtimes\n",
    "print(\"Cross-Validation Runtime:\", end_time_cv - start_time_cv, \"seconds\")\n",
    "print(\"Ensemble Cross-Validation Runtime:\", end_time_ensemble_cv - start_time_ensemble_cv, \"seconds\")\n",
    "print(\"Fit Runtime:\", end_time_fit - start_time_fit, \"seconds\")\n",
    "print(\"Prediction Runtime:\", end_time_preds - start_time_preds, \"seconds\")\n",
    "print(\"Accuracy Calculation Runtime:\", end_time_accuracy - start_time_accuracy, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6012b5c",
   "metadata": {},
   "source": [
    "When we perform the ensemble model of all of the logistic Regression, Random Forest, and Gradient Boosting Models we can see that the Ensemble Model has an accuracy of 0.9196299367510528 or 91.96% accurate when predicting for the outcome of whether the customer will be a safe borrower or not.\n",
    "\n",
    "When each of the models are combined, this gives us another issue of oversampling and over fitting to the model. This is partially because all models except for the Gradient Boost Model have been over fitted to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0abca8",
   "metadata": {},
   "source": [
    "### Up and Down Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "03189c3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution (Before):\n",
      "0    226132\n",
      "1     19876\n",
      "Name: TARGET, dtype: int64\n",
      "Accuracy (Original): 0.6838203014487099\n",
      "Accuracy (Upsampled): 0.7884493439344422\n",
      "Accuracy (Downsampled): 0.6838203014487099\n",
      "Upsampled Training Runtime: 454.61707830429077 seconds\n",
      "Upsampled Prediction Runtime: 2.442786931991577 seconds\n",
      "Upsampled Accuracy Calculation Runtime: 0.017435789108276367 seconds\n",
      "Downsampled Training Runtime: 47.265679121017456 seconds\n",
      "Downsampled Prediction Runtime: 2.351642370223999 seconds\n",
      "Downsampled Accuracy Calculation Runtime: 0.004544496536254883 seconds\n",
      "Original Prediction Runtime: 1.99517822265625 seconds\n",
      "Original Accuracy Calculation Runtime: 0.008304834365844727 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Analyze class distribution in the training set\n",
    "class_counts = y_train.value_counts()\n",
    "print(\"Class Distribution (Before):\")\n",
    "print(class_counts)\n",
    "\n",
    "# Upsample the minority class\n",
    "df_majority = X_train[y_train == 0]\n",
    "df_minority = X_train[y_train == 1]\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "\n",
    "X_train_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "y_train_upsampled = pd.Series([0] * len(df_majority) + [1] * len(df_minority_upsampled))\n",
    "\n",
    "# Downsample the majority class\n",
    "df_majority_downsampled = resample(df_majority, replace=False, n_samples=len(df_minority), random_state=42)\n",
    "\n",
    "X_train_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "y_train_downsampled = pd.Series([0] * len(df_majority_downsampled) + [1] * len(df_minority))\n",
    "\n",
    "# Train and evaluate models on upsampled and downsampled data\n",
    "model = ensemble_model  # Initialize the Ensemble model created\n",
    "\n",
    "# Train on upsampled data\n",
    "start_time_upsampled = time.time()\n",
    "model.fit(X_train_upsampled, y_train_upsampled)\n",
    "end_time_upsampled = time.time()\n",
    "\n",
    "# Make predictions on upsampled data\n",
    "start_time_pred_upsampled = time.time()\n",
    "y_pred_upsampled = model.predict(X_val)\n",
    "end_time_pred_upsampled = time.time()\n",
    "\n",
    "# Calculate accuracy on upsampled data\n",
    "start_time_accuracy_upsampled = time.time()\n",
    "accuracy_upsampled = accuracy_score(y_val, y_pred_upsampled)\n",
    "end_time_accuracy_upsampled = time.time()\n",
    "\n",
    "# Train on downsampled data\n",
    "start_time_downsampled = time.time()\n",
    "model.fit(X_train_downsampled, y_train_downsampled)\n",
    "end_time_downsampled = time.time()\n",
    "\n",
    "# Make predictions on downsampled data\n",
    "start_time_pred_downsampled = time.time()\n",
    "y_pred_downsampled = model.predict(X_val)\n",
    "end_time_pred_downsampled = time.time()\n",
    "\n",
    "# Calculate accuracy on downsampled data\n",
    "start_time_accuracy_downsampled = time.time()\n",
    "accuracy_downsampled = accuracy_score(y_val, y_pred_downsampled)\n",
    "end_time_accuracy_downsampled = time.time()\n",
    "\n",
    "# Compute predictions for original data\n",
    "start_time_pred_original = time.time()\n",
    "y_pred_original = model.predict(X_val)\n",
    "end_time_pred_original = time.time()\n",
    "\n",
    "# Calculate accuracy on original data\n",
    "start_time_accuracy_original = time.time()\n",
    "accuracy_original = accuracy_score(y_val, y_pred_original)\n",
    "end_time_accuracy_original = time.time()\n",
    "\n",
    "# Print model performance and runtimes\n",
    "print(\"Accuracy (Original):\", accuracy_original)\n",
    "print(\"Accuracy (Upsampled):\", accuracy_upsampled)\n",
    "print(\"Accuracy (Downsampled):\", accuracy_downsampled)\n",
    "\n",
    "print(\"Upsampled Training Runtime:\", end_time_upsampled - start_time_upsampled, \"seconds\")\n",
    "print(\"Upsampled Prediction Runtime:\", end_time_pred_upsampled - start_time_pred_upsampled, \"seconds\")\n",
    "print(\"Upsampled Accuracy Calculation Runtime:\", end_time_accuracy_upsampled - start_time_accuracy_upsampled, \"seconds\")\n",
    "\n",
    "print(\"Downsampled Training Runtime:\", end_time_downsampled - start_time_downsampled, \"seconds\")\n",
    "print(\"Downsampled Prediction Runtime:\", end_time_pred_downsampled - start_time_pred_downsampled, \"seconds\")\n",
    "print(\"Downsampled Accuracy Calculation Runtime:\", end_time_accuracy_downsampled - start_time_accuracy_downsampled, \"seconds\")\n",
    "\n",
    "print(\"Original Prediction Runtime:\", end_time_pred_original - start_time_pred_original, \"seconds\")\n",
    "print(\"Original Accuracy Calculation Runtime:\", end_time_accuracy_original - start_time_accuracy_original, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b10ae4b",
   "metadata": {},
   "source": [
    "Within our Ensemble Model we see that the method that has the highest accuracy is when we use the Upsample dataset with an accuracy of 0.7884493439344422 or 78.84%. The original and downsampled dataset have an accuracy of 0.6838203014487099 or 68.38%. The Upsample data will now be used within our hyper parameters and evaluation of the model and features.These percentages show us that there is less overfitting happening because of the diversity within the percentages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69996a6d",
   "metadata": {},
   "source": [
    "### Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a1235d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 14/14 [07:39<00:00, 32.79s/it], ETA: 0s\n",
      "100%|█████████████████████████| 452264/452264 [54:00<00:00, 139.54it/s], ETA: 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'model1__max_depth': None, 'model1__min_samples_leaf': 1, 'model1__min_samples_split': 2, 'model1__n_estimators': 100, 'model2__C': 1.0, 'model2__penalty': 'l2', 'model2__solver': 'liblinear'}\n",
      "Best Score: 0.7919622167583535\n",
      "Accuracy: 0.890493146675772\n",
      "Grid Search Runtime: 459.12626457214355 seconds\n",
      "Fit Runtime: 4.412505865097046 seconds\n",
      "Prediction Runtime: 4.412505865097046 seconds\n",
      "Accuracy Calculation Runtime: 0.021256446838378906 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the hyperparameters and their search space\n",
    "param_grid = {\n",
    "    'model1__n_estimators': [50, 100],\n",
    "    'model1__max_depth': [None],\n",
    "    'model1__min_samples_split': [2],\n",
    "    'model1__min_samples_leaf': [1],\n",
    "    'model2__C': [1.0],\n",
    "    'model2__penalty': ['l2'],\n",
    "    'model2__solver': ['liblinear']\n",
    "}\n",
    "\n",
    "# Reduce the number of cross-validation folds\n",
    "cv = 2\n",
    "\n",
    "# Split the training data into a smaller subset\n",
    "X_train_subset, _, y_train_subset, _ = train_test_split(X_train_upsampled, y_train_upsampled, train_size=0.5, random_state=42)\n",
    "\n",
    "# Initialize base estimators\n",
    "model1 = RandomForestClassifier(n_estimators=50, random_state=42)  # Reduced number of estimators\n",
    "model2 = LogisticRegression(random_state=42, max_iter=1000)  # Increased max_iter for faster convergence\n",
    "model3 = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Initialize ensemble model\n",
    "ensemble_model = VotingClassifier(estimators=[('model1', model1),\n",
    "                                              ('model2', model2),\n",
    "                                              ('model3', model3)])\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "start_time_search = time.time()\n",
    "grid_search = GridSearchCV(ensemble_model, param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Wrap the grid search with tqdm and display progress and ETA\n",
    "with tqdm(total=cv * len(grid_search.param_grid), ncols=80,\n",
    "          bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}], ETA: {remaining_s:.0f}s') as pbar:\n",
    "    grid_search.fit(X_train_subset, y_train_subset)\n",
    "    pbar.update(cv * len(grid_search.param_grid))  # Manually update progress bar to completion\n",
    "\n",
    "end_time_search = time.time()\n",
    "\n",
    "# Get the best hyperparameter values and model performance\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_rf_params = {k.replace('model1__', ''): v for k, v in best_params.items() if k.startswith('model1__')}\n",
    "best_lr_params = {k.replace('model2__', ''): v for k, v in best_params.items() if k.startswith('model2__')}\n",
    "best_model = VotingClassifier(estimators=[('model1', RandomForestClassifier(**best_rf_params, random_state=42)),\n",
    "                                          ('model2', LogisticRegression(**best_lr_params, random_state=42, max_iter=1000)),\n",
    "                                          ('model3', GradientBoostingClassifier(**best_rf_params, random_state=42))])\n",
    "\n",
    "# Wrap the fitting process with tqdm and display progress and ETA\n",
    "with tqdm(total=len(X_train_upsampled), ncols=80,\n",
    "          bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}], ETA: {remaining_s:.0f}s') as pbar:\n",
    "    best_model.fit(X_train_upsampled, y_train_upsampled)\n",
    "    pbar.update(len(X_train_upsampled))  # Manually update progress bar to completion\n",
    "\n",
    "# Make predictions using the best model\n",
    "start_time_pred = time.time()\n",
    "y_pred = best_model.predict(X_val)\n",
    "end_time_pred = time.time()\n",
    "\n",
    "# Evaluate the model performance\n",
    "start_time_accuracy = time.time()\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "end_time_accuracy = time.time()\n",
    "\n",
    "# Print the best hyperparameters and model performance\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the runtimes\n",
    "print(\"Grid Search Runtime:\", end_time_search - start_time_search, \"seconds\")\n",
    "print(\"Fit Runtime:\", end_time_pred - start_time_pred, \"seconds\")\n",
    "print(\"Prediction Runtime:\", end_time_pred - start_time_pred, \"seconds\")\n",
    "print(\"Accuracy Calculation Runtime:\", end_time_accuracy - start_time_accuracy, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c27ede1",
   "metadata": {},
   "source": [
    "After using hyper parameters, we see a couple of interesting observations. The first of which is that this process takes a long time to complete. Taking about 10 minutes to compute.\n",
    "\n",
    "Within the best hyperparameters for modeling we see that\n",
    "\n",
    "\n",
    "* model1__max_depth: In our scenario, it is set to None, meaning that there is no maximum depth limit.\n",
    "\n",
    "* model1__min_samples_leaf: Here, it is set to 1, meaning each leaf node should have at least one sample.\n",
    "\n",
    "* model1__min_samples_split: It is set to 2, indicating that a node must have at least 2 samples to be split.  It may have more, but it must be a minimum of 2.\n",
    "\n",
    "* model1__n_estimators: The best value found during the grid search is 100. This means that it takes about 100 decision trees to come up with the best parameter of the model.\n",
    "\n",
    "* model2__C: This is used for the combination of the Logisitic Regtression within our model. The best value is 1.\n",
    "\n",
    "* model2__penalty:  The best choice is l2, which refers to ridge regularization.This ridge regularization may have also been thrown off because of the parameters set to reduce computation time and capacity.\n",
    "\n",
    "* model2__solver: The best choice is liblinear, which is suitable for small datasets. This means that this model is going to have the best results when performed on small or medium datasets, rather than a large one.\n",
    "\n",
    "\n",
    "\n",
    "With the best score being 0.7919622167583535 meaning that the best score that can be achieved within the ensemble model is about .79. Meaning that the best Ensemble model acheived an average accuracy during cross validation within the search. This means that the model performs extremely well across the different data types.\n",
    "\n",
    "With best accuracy of  0.890493146675772 meaning that in the best case scenario this model will be having the proportion of correct classifications with an unkown dataset of about .89 correct classifications. This means that at the best this model will still classify about .89 of the dataset correctly. While this may be an improvement from our other models, this is still alarming that the model needed to be less over fit to the data provided into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ca8df",
   "metadata": {},
   "source": [
    "### Evaluating the Best of the Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6f8426ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Performance:\n",
      "AUC: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    226132\n",
      "           1       1.00      1.00      1.00     19876\n",
      "\n",
      "    accuracy                           1.00    246008\n",
      "   macro avg       1.00      1.00      1.00    246008\n",
      "weighted avg       1.00      1.00      1.00    246008\n",
      "\n",
      "Train Set Performance Runtime: 14.746994495391846 seconds\n",
      "Test Set Performance:\n",
      "AUC: 0.5319638928664842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     56554\n",
      "           1       0.18      0.10      0.13      4949\n",
      "\n",
      "    accuracy                           0.89     61503\n",
      "   macro avg       0.55      0.53      0.54     61503\n",
      "weighted avg       0.86      0.89      0.88     61503\n",
      "\n",
      "Test Set Performance Runtime: 3.51649808883667 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Train set performance\n",
    "start_time_train = time.time()\n",
    "train_pred = best_model.predict(X_train)\n",
    "train_auc = roc_auc_score(y_train, train_pred)\n",
    "end_time_train = time.time()\n",
    "\n",
    "# Print train set performance and runtime\n",
    "print(\"Train Set Performance:\")\n",
    "print(\"AUC:\", train_auc)\n",
    "print(classification_report(y_train, train_pred))\n",
    "print(\"Train Set Performance Runtime:\", end_time_train - start_time_train, \"seconds\")\n",
    "\n",
    "# Test set performance\n",
    "start_time_test = time.time()\n",
    "test_pred = best_model.predict(X_val)\n",
    "test_auc = roc_auc_score(y_val, test_pred)\n",
    "end_time_test = time.time()\n",
    "\n",
    "# Print test set performance and runtime\n",
    "print(\"Test Set Performance:\")\n",
    "print(\"AUC:\", test_auc)\n",
    "print(classification_report(y_val, test_pred))\n",
    "print(\"Test Set Performance Runtime:\", end_time_test - start_time_test, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e904695e",
   "metadata": {},
   "source": [
    "Under the best parameters set for the Ensemble Modeling\n",
    "\n",
    "The Train Set\n",
    "* Has an AUC of 1.0. Meaning that the models predictive powers seem to be a low discriminative power of the model. Indication that this Ensemble Model is over fitted to the data set. This is not a good measurement as it signals that it is just as comparable to random sampling.\n",
    "* The precision, recall, and F1 score for the majority class of 0 (Those who do not default) are all 1.0. Very high meaning that the model performs well in identifying the majority class, perfection.\n",
    "* The precision, recall, and F1 score for the minority class of 1 (Those who do default) are at 1.0. Meaning that the model is a perfect classifier of those that are safe to lend to.\n",
    "* This train set gives us a 100% accuracy rating. This is a suspicious measurement as the model is potentially over fitting to the training set almost entirely, despite going through the process of cross validation.\n",
    "\n",
    "The Test Set\n",
    "* AUC of Test: 0.5319638928664842. This shows us that within the test set, the model does have a discrimatory power, but it is relevatively low. It does show us that although it may be low, against the test set there is a slight increase from being away from nearly random guessing. Not as high as it could be though.\n",
    "* The precision, recall, and F1 score are  0.92, 0.96, and 0.94 when the class of 0 (Those who are save borrowers). This means that the model predicts the class of 0 not well.\n",
    "* The precision, recall, and F1 score are  0.18, 0.10, and 0.13  when the class of 1 (Those who are NOT save borrowers). This means that the model predicts the class of 1 moderately. This is a disadvantage to our model because we are wanting it to be trained to better predict those that would be classified as 1 as knowing who will default on their loans.\n",
    "* We see that because of the macro average and the weighted average they are unbalanced between the classes. \n",
    "* The accuracy is 0.89 or 89% which again shows us that although there are some improvements with this model from preventing over fitting, it still does have a tendency to over fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446667e1",
   "metadata": {},
   "source": [
    "### Features of the Best Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6a44fdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Feature     model1      model2     model3  \\\n",
      "27                EXT_SOURCE_2 0.09877625 -0.00000771 0.11965889   \n",
      "28                EXT_SOURCE_3 0.09503074 -0.00000725 0.12221178   \n",
      "7                   DAYS_BIRTH 0.05982140  0.00000206 0.06640491   \n",
      "10             DAYS_ID_PUBLISH 0.05542707  0.00003227 0.06239986   \n",
      "9            DAYS_REGISTRATION 0.05414072  0.00001582 0.06051397   \n",
      "0                   SK_ID_CURR 0.05280328  0.00000103 0.06084362   \n",
      "8                DAYS_EMPLOYED 0.05385393 -0.00000093 0.05723017   \n",
      "4                  AMT_ANNUITY 0.05442446  0.00001633 0.05342831   \n",
      "33      DAYS_LAST_PHONE_CHANGE 0.05312109  0.00018206 0.05381501   \n",
      "6   REGION_POPULATION_RELATIVE 0.04318285 -0.00000008 0.04957898   \n",
      "\n",
      "    Average_Importance  \n",
      "27          0.07280914  \n",
      "28          0.07241176  \n",
      "7           0.04207612  \n",
      "10          0.03928640  \n",
      "9           0.03822350  \n",
      "0           0.03788264  \n",
      "8           0.03702772  \n",
      "4           0.03595637  \n",
      "33          0.03570605  \n",
      "6           0.03092058  \n"
     ]
    }
   ],
   "source": [
    "# #Feature importance\n",
    "# feature_importances = best_model.feature_importances_\n",
    "\n",
    "# #Create a DataFrame to store the feature importances\n",
    "# importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "# #Sort the DataFrame by importance in descending order\n",
    "# importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# #Display the top 10 most important features\n",
    "# print(importance_df.head(20))\n",
    "\n",
    "\n",
    "# Calculate feature importances for each individual model\n",
    "importance_df = pd.DataFrame({'Feature': X_train.columns})\n",
    "\n",
    "for name, model in best_model.named_estimators_.items():\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importance_df[name] = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        importance_df[name] = model.coef_[0]\n",
    "    else:\n",
    "        importance_df[name] = 0\n",
    "\n",
    "# Calculate the average importance across all individual models\n",
    "importance_df['Average_Importance'] = importance_df.iloc[:, 1:].mean(axis=1)\n",
    "\n",
    "# Sort the DataFrame by average importance in descending order\n",
    "importance_df = importance_df.sort_values('Average_Importance', ascending=False)\n",
    "\n",
    "# Display the top 20 most important features\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebcc885",
   "metadata": {},
   "source": [
    "From this output, we learn that the top 10 most important features from our ensemble model when seeing if someone is safe to lend money to are based on\n",
    "\n",
    "\n",
    "* Normalized score from external data source\n",
    "* Client's age in days at the time of application\n",
    "* How many days before the application did client change the identity document\n",
    "* How many days before the application did client change their registration\n",
    "* ID of loan in our sample\n",
    "* How many days before the application the person started current employment\n",
    "* Loan annuity\n",
    "* Number of days since the client last changed their phone number\n",
    "* Normalized population of region where client lives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb3580f",
   "metadata": {},
   "source": [
    "### Prediction on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "39e057a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on the test set\n",
    "test_predictions = best_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f558e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": test_data[\"SK_ID_CURR\"], \n",
    "    \"TARGET\": test_predictions\n",
    "})\n",
    "\n",
    "#Remove duplicate SK_ID_CURR values\n",
    "submission = submission.drop_duplicates(subset=\"SK_ID_CURR\", keep=\"first\")\n",
    "\n",
    "#Save the submission DataFrame to a CSV file\n",
    "submission.to_csv(\"submission_ensemble2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9265ee1",
   "metadata": {},
   "source": [
    "When we put this dataset into Kaggle, we return a Kaggle score of .52188. This is an improvement from the Logistic and Random Forest, but it still is signaling toward potential over fitting and random guessing from the model because of the low Kaggle score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a0dbf0",
   "metadata": {},
   "source": [
    "# Model Performances Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e26cc1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Performance Evaluation (Based on Best)</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Gradient Boosting Model</td>\n",
       "      <td>Logistic Regression Model</td>\n",
       "      <td>Random Forest Classification</td>\n",
       "      <td>Ensemble Model</td>\n",
       "      <td>Naïve Bayes Model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sample That gave Best Accuracy (Original, Upsa...</td>\n",
       "      <td>Upsampled</td>\n",
       "      <td>Original</td>\n",
       "      <td>Upsampled</td>\n",
       "      <td>Upsampled</td>\n",
       "      <td>Original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best Hyperparameters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 2, ...</td>\n",
       "      <td>{'model1__max_depth': None, 'model1__min_samp...</td>\n",
       "      <td>{'alpha': 0.1, 'binarize': 1.0, 'fit_prior': T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Score</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.919202</td>\n",
       "      <td>0.990052</td>\n",
       "      <td>0.791962</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best Accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.919516</td>\n",
       "      <td>0.919419</td>\n",
       "      <td>0.890493</td>\n",
       "      <td>0.919532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Best Train Set Performance AUC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499998</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Best Train Set Performance Accuracy</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Best Train Set Precision, Recall, F1 Score for...</td>\n",
       "      <td>0.17346568212080862, 0.5791068902808648, 0.26...</td>\n",
       "      <td>0.92      1.00      0.96</td>\n",
       "      <td>1.00      1.00      1.00</td>\n",
       "      <td>1.00      1.00      1.00</td>\n",
       "      <td>0.17142857142857143\\n 0.003637098403717923\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Best Train Set Precision, Recall, F1 Score for...</td>\n",
       "      <td>0.826534317879192, 0.420893109719136, 0.73303...</td>\n",
       "      <td>0.00      0.00      0.00</td>\n",
       "      <td>1.00      1.00      1.00</td>\n",
       "      <td>1.00      1.00      1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Best Train Set Performance Runtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.22581863403320312 seconds</td>\n",
       "      <td>9.18987774848938 seconds</td>\n",
       "      <td>14.746994495391846 seconds</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Best Test Set Performance AUC</td>\n",
       "      <td>0.668819</td>\n",
       "      <td>0.499991</td>\n",
       "      <td>0.507037</td>\n",
       "      <td>0.531964</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Best Test Set Performance Accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Best Test Set Performance Runtime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03416752815246582 seconds</td>\n",
       "      <td>2.0379745960235596 seconds</td>\n",
       "      <td>3.51649808883667 seconds</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Best Test Set Precision, Recall, F1 Score for ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92      1.00      0.96</td>\n",
       "      <td>0.92      1.00      0.96</td>\n",
       "      <td>0.92      0.96      0.94</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Best Test Set Precision, Recall, F1 Score for ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00      0.00      0.00</td>\n",
       "      <td>0.48      0.02      0.03</td>\n",
       "      <td>0.18      0.10      0.13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Top 10 Features in Relation to Customer Borrow...</td>\n",
       "      <td>EXT_SOURCE_3, EXT_SOURCE_2 , AMT_REQ_CREDIT_BU...</td>\n",
       "      <td>DAYS_LAST_PHONE_CHANGE, DAYS_ID_PUBLISH, DAYS_...</td>\n",
       "      <td>EXT_SOURCE_2, EXT_SOURCE_3, DAYS_BIRTH , DAYS_...</td>\n",
       "      <td>EXT_SOURCE_2 , EXT_SOURCE_3 , DAYS_BIRTH, DAYS...</td>\n",
       "      <td>AMT_INCOME_TOTAL:,\\nAMT_CREDIT:, AMT_ANNUITY:,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kaggle Score</td>\n",
       "      <td>0.655604</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50195</td>\n",
       "      <td>0.52188</td>\n",
       "      <td>0.502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model Performance Evaluation (Based on Best)  \\\n",
       "0                                                 NaN   \n",
       "1   Sample That gave Best Accuracy (Original, Upsa...   \n",
       "2                                Best Hyperparameters   \n",
       "3                                          Best Score   \n",
       "4                                       Best Accuracy   \n",
       "5                      Best Train Set Performance AUC   \n",
       "6                 Best Train Set Performance Accuracy   \n",
       "7   Best Train Set Precision, Recall, F1 Score for...   \n",
       "8   Best Train Set Precision, Recall, F1 Score for...   \n",
       "9                  Best Train Set Performance Runtime   \n",
       "10                      Best Test Set Performance AUC   \n",
       "11                 Best Test Set Performance Accuracy   \n",
       "12                  Best Test Set Performance Runtime   \n",
       "13  Best Test Set Precision, Recall, F1 Score for ...   \n",
       "14  Best Test Set Precision, Recall, F1 Score for ...   \n",
       "15  Top 10 Features in Relation to Customer Borrow...   \n",
       "16                                       Kaggle Score   \n",
       "\n",
       "                                           Unnamed: 1  \\\n",
       "0                             Gradient Boosting Model   \n",
       "1                                           Upsampled   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                            0.744094   \n",
       "7    0.17346568212080862, 0.5791068902808648, 0.26...   \n",
       "8    0.826534317879192, 0.420893109719136, 0.73303...   \n",
       "9                                                 NaN   \n",
       "10                                           0.668819   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15  EXT_SOURCE_3, EXT_SOURCE_2 , AMT_REQ_CREDIT_BU...   \n",
       "16                                           0.655604   \n",
       "\n",
       "                                           Unnamed: 2  \\\n",
       "0                           Logistic Regression Model   \n",
       "1                                            Original   \n",
       "2   {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...   \n",
       "3                                            0.919202   \n",
       "4                                            0.919516   \n",
       "5                                            0.499998   \n",
       "6                                                0.92   \n",
       "7                            0.92      1.00      0.96   \n",
       "8                            0.00      0.00      0.00   \n",
       "9                         0.22581863403320312 seconds   \n",
       "10                                           0.499991   \n",
       "11                                               0.92   \n",
       "12                        0.03416752815246582 seconds   \n",
       "13                           0.92      1.00      0.96   \n",
       "14                           0.00      0.00      0.00   \n",
       "15  DAYS_LAST_PHONE_CHANGE, DAYS_ID_PUBLISH, DAYS_...   \n",
       "16                                                0.5   \n",
       "\n",
       "                                           Unnamed: 3  \\\n",
       "0                        Random Forest Classification   \n",
       "1                                           Upsampled   \n",
       "2   {'n_estimators': 100, 'min_samples_split': 2, ...   \n",
       "3                                            0.990052   \n",
       "4                                            0.919419   \n",
       "5                                                   1   \n",
       "6                                                   1   \n",
       "7                           1.00      1.00      1.00    \n",
       "8                            1.00      1.00      1.00   \n",
       "9                            9.18987774848938 seconds   \n",
       "10                                           0.507037   \n",
       "11                                               0.92   \n",
       "12                         2.0379745960235596 seconds   \n",
       "13                           0.92      1.00      0.96   \n",
       "14                           0.48      0.02      0.03   \n",
       "15  EXT_SOURCE_2, EXT_SOURCE_3, DAYS_BIRTH , DAYS_...   \n",
       "16                                            0.50195   \n",
       "\n",
       "                                           Unnamed: 4  \\\n",
       "0                                      Ensemble Model   \n",
       "1                                           Upsampled   \n",
       "2    {'model1__max_depth': None, 'model1__min_samp...   \n",
       "3                                            0.791962   \n",
       "4                                            0.890493   \n",
       "5                                                   1   \n",
       "6                                                   1   \n",
       "7                            1.00      1.00      1.00   \n",
       "8                            1.00      1.00      1.00   \n",
       "9                          14.746994495391846 seconds   \n",
       "10                                           0.531964   \n",
       "11                                               0.89   \n",
       "12                           3.51649808883667 seconds   \n",
       "13                          0.92      0.96      0.94    \n",
       "14                           0.18      0.10      0.13   \n",
       "15  EXT_SOURCE_2 , EXT_SOURCE_3 , DAYS_BIRTH, DAYS...   \n",
       "16                                            0.52188   \n",
       "\n",
       "                                           Unnamed: 5  \n",
       "0                                   Naïve Bayes Model  \n",
       "1                                            Original  \n",
       "2   {'alpha': 0.1, 'binarize': 1.0, 'fit_prior': T...  \n",
       "3                                                 NaN  \n",
       "4                                            0.919532  \n",
       "5                                                 NaN  \n",
       "6                                             0.91841  \n",
       "7    0.17142857142857143\\n 0.003637098403717923\\n ...  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15  AMT_INCOME_TOTAL:,\\nAMT_CREDIT:, AMT_ANNUITY:,...  \n",
       "16                                              0.502  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running this code that will display a summary table of all of the metrics that we have used to evaluate our models.\n",
    "\n",
    "import pandas as pd\n",
    "#!pip install openpyxl\n",
    "\n",
    "\n",
    "\n",
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(r\"C:\\Users\\jusha\\Documents\\IS 6812 MSBA Capstone 1\\Models Summary Modeling Assignment Excel.xlsx\")\n",
    "\n",
    "# Display the DataFrame as a table\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fdb073",
   "metadata": {},
   "source": [
    "Based on the AUC and Kaggle score, we see that the best model that has been created was the Gradient Boosting Model. \n",
    "\n",
    "The Gradient Boosting Model gives a Kaggle score of .656 and an AUC of .669.\n",
    "\n",
    "These results show that the Gradient Boost Model created will provide a sufficient amount of accurate predictions, while the other models suffer from being over fitted. The other models created with lower AUC and lower Kaggle scores within the test set indicate that they are similar odds of simply guessing the outcome of the customer default status. The Gradient Boosting Model created will be the best one to use to determine which of the customers are going to default or if they are safe to approve a loan to. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee8ce2b",
   "metadata": {},
   "source": [
    "# Results Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f1a02d",
   "metadata": {},
   "source": [
    "After performing our Gradient Boost modeling processes we have discovered useful findings for Home Credit to consdier when knowing attributes about a client that is likely to default.\n",
    "\n",
    "Attributes about a client that commonly infer a customer defaulting are if: \n",
    "\n",
    "* There are many enquiries to Credit Bureau 1 day before application. \n",
    "\n",
    "* The client provided work phone as their phone contact information.\n",
    "\n",
    "* The client is located in a low rated regions. \n",
    "\n",
    "* The loan is used for high price of goods that are bought by the client.\n",
    "\n",
    "* There are many enquiries to Credit Bureau 1 hour before application.\n",
    "\n",
    "* The permanent address provided by the client is not the same as the contact address provided by the client.\n",
    "\n",
    "By knowing each of these, this solves our business problem by knowing which demographics or audiences who may not be the most safe to loan to. By now knowing each of these attributes and using the model, this will help to lower risk of lending to someone who will not repay their loan, thus increasing the cost. By only approving loans to customers who are predicted to repay their loan, Home Credit can increase their revenue. By increasing revenue and lowering costs, in the end profits will be increased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b80639",
   "metadata": {},
   "source": [
    "# Justin Hamilton Individual Contribution Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa404e6",
   "metadata": {},
   "source": [
    "***Justin Hamilton:*** I first ran a trial model for the Gradient Boost, Logistic Regression, Random Forest Classifier, and Ensemble Model. I created this in my own document and then shared it within the group. After seeing the rest of the groups efforts, I then compiled all of the codes and models into this document and organized the files. I wrote the interpretations within this notebook and created the Logistic, Random Forest, and Ensemble Models. I wrote up the summary rough draft, made the interpretations throughout the analysis, and compiled this whole document neatly for submission. I also wrote the model hyper parameters, evaluations, and feature engineering for each of the models to come to a conclusion. Wrote the results summary of the modeling.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "713px",
    "left": "10px",
    "top": "150px",
    "width": "1442px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
